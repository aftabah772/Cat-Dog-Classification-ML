{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification_CatDog_Example.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Xtp4ndDEE1kp"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwP-MbcUajW_"
      },
      "source": [
        "#Experience AI\n",
        "##Hands-on Expertise in Machine Learning & Deep Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La9Rh65MdTV6"
      },
      "source": [
        "##Overview of the notebook\n",
        "\n",
        "### . Have your images folders ready and connect it\n",
        "\n",
        "### . Building a simple CNN model for Cat Dog classification\n",
        "\n",
        "\n",
        "> Step 1: Setup libraries\n",
        "\n",
        "> Step 2: Load and pre-process data\n",
        "\n",
        "> Step 3: Create CNN model\n",
        "\n",
        "> Step 4: Compile model\n",
        "\n",
        "> Step 5: Train model\n",
        "\n",
        "> Step 6: Save/Load model\n",
        "\n",
        "> Step 7: Evaluate model\n",
        "\n",
        "### C. Training state-of-the-art network\n",
        "\n",
        "> Step 1: Import Library\n",
        "\n",
        "> Step 2: Create Model using ResNet50 Architecture\n",
        "\n",
        "> Step 3: Compile Model\n",
        "\n",
        "> Step 4: Train Model\n",
        "\n",
        "> Step 5: Evaluate Model\n",
        "\n",
        "### D. Transfer learning from ImageNet and fine-tuning on our dataset\n",
        "\n",
        "> Step 1. Preprocess Dataset w.r.t ResNet architecture\n",
        "\n",
        "> Step 2. Load the ResNet50 architecture with Pretrained ImageNet weights\n",
        "\n",
        "> Step 3. Modify ResNet50 architecture\n",
        "\n",
        "> Step 4. Compile ResNet50 architecture\n",
        "\n",
        "> Step 5. Train ResNet50 architecture\n",
        "\n",
        "### E. Fine Tuning ResNet50 Architecture\n",
        "\n",
        "> Step 1. Set Trainable Parameters\n",
        "\n",
        "> Step 2. Compile Model\n",
        "\n",
        "> Step 3. Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8QWOfibdnR2"
      },
      "source": [
        "# A. Connect your images folder for classificaton\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lt7pnnSemW-7"
      },
      "source": [
        "# B. Building a simple CNN model for Cat Dog classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca02pjyfd1tK"
      },
      "source": [
        "## Step 1: Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQGrFL-Sd5hS"
      },
      "source": [
        "#Import libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Import Image Data Generator, which allow us to create data generator for images\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSte3rVcd8UC"
      },
      "source": [
        "## Step 2: Load and pre-process data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hl7F2JXLbTqd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72ec508d-b1fb-48fc-dac3-62ca5f56b20c"
      },
      "source": [
        "#Define Parameters for Model Training\n",
        "imgSize = 224 #Set Image size to be used as model input\n",
        "imgChannel = 3 #Set no. of channel in image i.e. 1 if grayscale, 3 if RGB\n",
        "batch_size = 32 #Set number of images to be used as a set of model training/validation/testing\n",
        "eps = 50 #Set number of epoches to train the model\n",
        "\n",
        "# Create an Image Data Generator\n",
        "input_imgen = ImageDataGenerator(rotation_range=0, width_shift_range=0.0,\n",
        "                                  height_shift_range=0.0, shear_range=0.0, zoom_range=0.0,\n",
        "                                  fill_mode='nearest', rescale = 1./255,\n",
        "                                  validation_split=0.1)\n",
        "\n",
        "trainDir = './catsvsdogs/train/' #Specify path of training data directory\n",
        "testDir = './catsvsdogs/test/' #Specify path of testing data directory\n",
        "\n",
        "#Tell Image generator to load data from given directory and preprocess data with the mentioned properties\n",
        "\n",
        "print('Training Dataset:')\n",
        "trainGen = input_imgen.flow_from_directory(\n",
        "      directory = trainDir, #Path to directory\n",
        "      target_size = (imgSize,imgSize), #Resize the images resolution to the desired size\n",
        "      color_mode = 'rgb', #Specify color mode i.e. RGB or Grayscale image\n",
        "      class_mode = 'binary', #Specify type of output, i.e. Binary for 2 classes, Categorical for more than 2 classes\n",
        "      batch_size = batch_size, #Specify batch size to be used\n",
        "      shuffle=True, #Set whether to shuffle dataset after every epoch\n",
        "      subset='training', #Specifiy the set of dataset\n",
        "      classes=[\"cat\",\"dog\"]) #Specify which classes should be considered in generator\n",
        "\n",
        "print('\\nValidation Dataset:')\n",
        "validGen = input_imgen.flow_from_directory(\n",
        "      directory = trainDir, #Path to directory\n",
        "      target_size = (imgSize,imgSize), #Resize the images resolution to the desired size\n",
        "      color_mode = 'rgb', #Specify color mode i.e. RGB or Grayscale image\n",
        "      class_mode = 'binary', #Specify type of output, i.e. Binary for 2 classes, Categorical for more than 2 classes\n",
        "      batch_size = batch_size, #Specify batch size to be used\n",
        "      shuffle=True, #Set whether to shuffle dataset after every epoch\n",
        "      subset='validation', #Specifiy the set of dataset\n",
        "      classes=[\"cat\",\"dog\"]) #Specify which classes should be considered in generator\n",
        "\n",
        "print('\\nTest Dataset:')\n",
        "testGen = input_imgen.flow_from_directory(\n",
        "      directory = testDir, #Path to directory\n",
        "      target_size = (imgSize,imgSize), #Resize the images resolution to the desired size\n",
        "      color_mode = 'rgb', #Specify color mode i.e. RGB or Grayscale image\n",
        "      class_mode = 'binary', #Specify type of output, i.e. Binary for 2 classes, Categorical for more than 2 classes\n",
        "      batch_size = batch_size, #Specify batch size to be used\n",
        "      shuffle=False, #Set whether to shuffle dataset after every epoch\n",
        "      #subset='validation', #Specifiy the set of dataset\n",
        "      classes=[\"cat\",\"dog\"]) #Specify which classes should be considered in generator\n",
        "\n",
        "#Run this code to check the values assigned to each class\n",
        "label_map = (trainGen.class_indices)\n",
        "print('\\nValue assigned to each class: ',label_map)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Dataset:\n",
            "Found 0 images belonging to 2 classes.\n",
            "\n",
            "Validation Dataset:\n",
            "Found 0 images belonging to 2 classes.\n",
            "\n",
            "Test Dataset:\n",
            "Found 0 images belonging to 2 classes.\n",
            "\n",
            "Value assigned to each class:  {'cat': 0, 'dog': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UnoG6sApz3x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "outputId": "b0b56409-1ca7-4dce-a793-bcfb4e660306"
      },
      "source": [
        "#Run this code to pick one batch from the training dataset\n",
        "images,labels = next(trainGen)\n",
        "\n",
        "#Display some glimpse of the picked batch data\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i])\n",
        "    plt.title(int(labels[i]))\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-c38034c1037f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"off\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsMC0EYGeI0G"
      },
      "source": [
        "## Step 3: Create CNN model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AN0OW3FZhBh0"
      },
      "source": [
        "Creating model using Sequential API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDGwnTN7fS74"
      },
      "source": [
        "# This code generate model using sequential model technique\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(imgSize,imgSize,imgChannel), padding=\"same\"))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding=\"same\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
        "model.add(Conv2D( 64, kernel_size=(3, 3), activation='relu', padding=\"same\"))\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding=\"same\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
        "#Global Average Pooling (GAP) is a pooling operation designed to replace fully connected layers in classical CNNs\n",
        "#In GAP, we take average value of the last feature map and flatten it into 1 dimensional hot-vector\n",
        "model.add(GlobalAveragePooling2D()) \n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHX0qbb-hG8b"
      },
      "source": [
        "Creating model using Functional API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pebHINyBpwpo"
      },
      "source": [
        "# # This code generate model using functional model technique\n",
        "# img_input = Input(shape=(imgSize, imgSize, imgChannel))\n",
        "# conv1 = Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same')(img_input)\n",
        "# conv2 = Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same')(conv1)\n",
        "# maxpool1 = MaxPooling2D(pool_size=(2, 2), padding='same')(conv2)\n",
        "# conv3 = Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same')(maxpool1)\n",
        "# conv4 = Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same')(conv3)\n",
        "# maxpool2 = MaxPooling2D(pool_size=(2, 2), padding='same')(conv4)\n",
        "# gap1 = GlobalAveragePooling2D()(maxpool2)\n",
        "# dense1 = Dense(64, activation='relu')(gap1)\n",
        "# dropout1 = Dropout(0.2)(dense1)\n",
        "# model_output = Dense(1, activation='sigmoid')(dropout1)\n",
        "\n",
        "# model = Model(img_input, model_output)\n",
        "# model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRaiBPgwebkp"
      },
      "source": [
        "## Step 4: Compile Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHU3JATrecIa"
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1ZqQFNCeqRi"
      },
      "source": [
        "## Step 5: Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTn5zq5IfEtd"
      },
      "source": [
        "history = model.fit(trainGen, \n",
        "                    batch_size=batch_size, \n",
        "                    epochs=20, \n",
        "                    shuffle=True, \n",
        "                    validation_data=validGen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKRVH9eol5Ez"
      },
      "source": [
        "##Plot model performance curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4O06Y1DRmR3Z"
      },
      "source": [
        "plt.style.use('seaborn')\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# summarize history for loss\n",
        "plt.figure()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPUbI4ZchzMi"
      },
      "source": [
        "## Step 6: Load/Save Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFfL_l7AiIx3"
      },
      "source": [
        "The trained model can be saved to google drive using this code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETIfouiQh6sB"
      },
      "source": [
        "# model.save('/content/drive/MyDrive/ClassificationExample/custom_model_50epoch.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taNETvRhiUN1"
      },
      "source": [
        "The trained model can also be loaded from google drive using this code for furture use, run this code to load model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZeliQWDvkwX"
      },
      "source": [
        "# model = keras.models.load_model(\"/content/drive/MyDrive/ClassificationExample/custom_model_50epoch.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDI-fe2OkBZO"
      },
      "source": [
        "## Step 7: Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgKBdDm3yI3a"
      },
      "source": [
        "#Use the trained model to make prediction on test dataset\n",
        "y_pred = model.predict(testGen,verbose=1)\n",
        "\n",
        "#Run this line to evaluate the model accuracy and loss on test dataset\n",
        "b = model.evaluate(testGen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u74UwpUuRDDj"
      },
      "source": [
        "#Apply threshold of 50% to round the results values\n",
        "y_pred[y_pred >= 0.5] = 1\n",
        "y_pred[y_pred < 0.5] = 0\n",
        "\n",
        "#Convert the array results to 1 dimensional hot vector, so that it can be used to compare with test dataset ground truth labels\n",
        "y_pred = y_pred.flatten()\n",
        "\n",
        "#Get the labels of the ground truth test dataset\n",
        "y_true = testGen.classes\n",
        "\n",
        "#Evaluate the model performance using metrics and display results\n",
        "print('\\nConfusion Matrix')\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "print('\\nClassification Report')\n",
        "print(classification_report(y_true, y_pred, digits=4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GNMtsVnuI03"
      },
      "source": [
        "#Pick one batch of the test dataset\n",
        "images,labels = next(testGen)\n",
        "\n",
        "y_pred_batch = model.predict(images)\n",
        "\n",
        "#Show some glimpse of the model prediction along with input test images\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i])\n",
        "    plt.title(int(y_pred_batch[i]))\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xtp4ndDEE1kp"
      },
      "source": [
        "# C. Training state-of-the-art networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMZ23QCWmqMr"
      },
      "source": [
        "## Step 1: Import Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RtkWc_7mlJc"
      },
      "source": [
        "#Import state-of-the-art ResNet50 architecture and input data preprocessing function\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JE-MYFKLmt3c"
      },
      "source": [
        "## Step 2: Create Model using ResNet50 Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tx0_A6CuE7CQ"
      },
      "source": [
        "ResNet = ResNet50(weights=None, include_top = False,input_shape=(224,224,3))\n",
        "ResNet.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0efvP9-F6BN"
      },
      "source": [
        "#Modify ResNet50 architecture according to our requirement (Cat, Dog Classification)\n",
        "x =  ResNet.output\n",
        "GAP = GlobalAveragePooling2D()(x)\n",
        "drop = Dropout(0.2)(GAP)\n",
        "out = Dense(1, activation='sigmoid')(drop)\n",
        "\n",
        "ResNet = Model(inputs = ResNet.input, outputs = out)\n",
        "ResNet.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDMCa7lWndgJ"
      },
      "source": [
        "## Step 3: Compile Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuz-bC6iFrqP"
      },
      "source": [
        "ResNet.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0isRxqEnkw3"
      },
      "source": [
        "## Step 4: Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OvZqhNZFuHM"
      },
      "source": [
        "history = ResNet.fit(trainGen, \n",
        "                    batch_size=batch_size,\n",
        "                    epochs=10, \n",
        "                    shuffle=True,\n",
        "                    validation_data=validGen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PF3BLJf1oIN5"
      },
      "source": [
        "Plot ResNet50 model performance curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5J5zvW3oEa3"
      },
      "source": [
        "plt.style.use('seaborn')\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# summarize history for loss\n",
        "plt.figure()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heEFl9nQoNOC"
      },
      "source": [
        "## Step 5: Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UP6cuVXXVD--"
      },
      "source": [
        "#Use the trained model to predict the results on test dataset\n",
        "y_pred = ResNet.predict(testGen,verbose=1)\n",
        "\n",
        "#Run this line to evaluate the model accuracy and loss on test dataset\n",
        "b = ResNet.evaluate(testGen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Petycg25F0pM"
      },
      "source": [
        "#Apply threshold of 50% to round the results values\n",
        "y_pred[y_pred >= 0.5] = 1\n",
        "y_pred[y_pred < 0.5] = 0\n",
        "\n",
        "#Convert the array results to 1 dimensional hot vector, so that it can be used to compare with test dataset ground truth labels\n",
        "y_pred = y_pred.flatten()\n",
        "\n",
        "#Get the labels of the ground truth test dataset\n",
        "y_true = testGen.classes\n",
        "\n",
        "#Evaluate the model performance using metrics and display results\n",
        "print('\\nConfusion Matrix')\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "print('\\nClassification Report')\n",
        "print(classification_report(y_true, y_pred, digits=4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsbvLebjaAI9"
      },
      "source": [
        "#Run this code to pick one batch from the training dataset\n",
        "images,labels = next(trainGen)\n",
        "y_pred_batch = ResNet.predict(images)\n",
        "\n",
        "#Display some glimpse of the picked batch data\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i])#.astype(np.uint8))\n",
        "    plt.title(int(y_pred_batch[i]))\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckVImPmHIKJc"
      },
      "source": [
        "# D. Transfer learning from ImageNet and fine-tuning on our dataet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToX1oRP5piTs"
      },
      "source": [
        "## Step 1. Preprocess Dataset w.r.t ResNet architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtvscdJFp0QV"
      },
      "source": [
        "ResNet use **\"preprocess_input\"** function to preprocess dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_M4VCqrYZQ4N"
      },
      "source": [
        "input_imgen = ImageDataGenerator( rotation_range=0, width_shift_range=0.0,\n",
        "                                  height_shift_range=0.0, shear_range=0.0, zoom_range=0.0,\n",
        "                                  fill_mode='nearest', rescale=None,\n",
        "                                  preprocessing_function=preprocess_input,\n",
        "                                  validation_split=0.1) #Define Image Generator\n",
        "                                 \n",
        "print('Training Dataset:')\n",
        "trainGen = input_imgen.flow_from_directory(\n",
        "      directory = trainDir, #Path to directory\n",
        "      target_size = (imgSize,imgSize), #Resize the images resolution to the desired size\n",
        "      color_mode = 'rgb', #Specify color mode i.e. RGB or Grayscale image\n",
        "      class_mode = 'binary', #Specify type of output, i.e. Binary for 2 classes, Categorical for more than 2 classes\n",
        "      batch_size = batch_size, #Specify batch size to be used\n",
        "      shuffle=True, #Set whether to shuffle dataset after every epoch\n",
        "      subset='training', #Specifiy the set of dataset\n",
        "      classes=[\"cat\",\"dog\"]) #Specify which classes should be considered in generator\n",
        "\n",
        "print('\\nValidation Dataset:')\n",
        "validGen = input_imgen.flow_from_directory(\n",
        "      directory = trainDir, #Path to directory\n",
        "      target_size = (imgSize,imgSize), #Resize the images resolution to the desired size\n",
        "      color_mode = 'rgb', #Specify color mode i.e. RGB or Grayscale image\n",
        "      class_mode = 'binary', #Specify type of output, i.e. Binary for 2 classes, Categorical for more than 2 classes\n",
        "      batch_size = batch_size, #Specify batch size to be used\n",
        "      shuffle=True, #Set whether to shuffle dataset after every epoch\n",
        "      subset='validation', #Specifiy the set of dataset\n",
        "      classes=[\"cat\",\"dog\"]) #Specify which classes should be considered in generator\n",
        "\n",
        "print('\\nTest Dataset:')\n",
        "testGen = input_imgen.flow_from_directory(\n",
        "      directory = testDir, #Path to directory\n",
        "      target_size = (imgSize,imgSize), #Resize the images resolution to the desired size\n",
        "      color_mode = 'rgb', #Specify color mode i.e. RGB or Grayscale image\n",
        "      class_mode = 'binary', #Specify type of output, i.e. Binary for 2 classes, Categorical for more than 2 classes\n",
        "      batch_size = batch_size, #Specify batch size to be used\n",
        "      shuffle=False, #Set whether to shuffle dataset after every epoch\n",
        "      #subset='validation', #Specifiy the set of dataset\n",
        "      classes=[\"cat\",\"dog\"]) #Specify which classes should be considered in generator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRPibM0rqJI8"
      },
      "source": [
        "## Step 2. Load the ResNet50 architecture with Pretrained ImageNet weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_L4GIcQIWGs"
      },
      "source": [
        "ResNet = ResNet50(weights='imagenet', include_top = False,input_shape=(224,224,3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NF65JFdqZJS"
      },
      "source": [
        "##Step 3. Modify ResNet50 architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_d1rRmLcIyTz"
      },
      "source": [
        "for layer in ResNet.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "x =  ResNet.output\n",
        "GAP = GlobalAveragePooling2D()(x)\n",
        "drop = Dropout(0.2)(GAP)\n",
        "out = Dense(1, activation='sigmoid')(drop)\n",
        "\n",
        "ResNet = Model(inputs = ResNet.input, outputs = out)\n",
        "ResNet.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtJKITwtqlgI"
      },
      "source": [
        "##Step 4. Compile ResNet50 architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXbPMRaGI1Ts"
      },
      "source": [
        "ResNet.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eyl5lDX8qpLS"
      },
      "source": [
        "##Step 5. Train ResNet50 architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qitg--znI3zM"
      },
      "source": [
        "history = ResNet.fit(trainGen, \n",
        "                    batch_size=batch_size,\n",
        "                    epochs=5, \n",
        "                    shuffle=True,\n",
        "                    validation_data=validGen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QjRQh_fqvsv"
      },
      "source": [
        "#E. Fine Tuning ResNet50 Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fcrm1evWrAvh"
      },
      "source": [
        "##Step 1. Set Trainable Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vld2fJfXbBJ5"
      },
      "source": [
        "ResNet.trainable = True\n",
        "ResNet.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01_QCKrRrH5l"
      },
      "source": [
        "##Step 2. Compile Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmNKy-GvcAnj"
      },
      "source": [
        "ResNet.compile(loss='binary_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.RMSprop(learning_rate = 1e-5),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oIyVrqvrNJe"
      },
      "source": [
        "##Step 3. Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iy_EOGhJb857"
      },
      "source": [
        "history = ResNet.fit(trainGen, \n",
        "                    batch_size=batch_size, \n",
        "                    #steps_per_epoch=len(trainGen)/batch_size, \n",
        "                    epochs=5, \n",
        "                    shuffle=True, \n",
        "                    #validation_steps=len(validGen)/batch_size, \n",
        "                    validation_data=validGen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1Y_oWUzt4K1"
      },
      "source": [
        "plt.style.use('seaborn')\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# summarize history for loss\n",
        "plt.figure()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}